{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c3243b-4e03-4934-aaaf-182e0b99d22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7ae495-265a-4974-8d5c-d26a2fe8d8f7",
   "metadata": {},
   "source": [
    "1.\n",
    "Implementar el algoritmo de pasaje a coordenadas cromáticas para librarnos de las variaciones de contraste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9bdc5d1-306c-45a6-aeea-fb8021eb0248",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cc_1_BGR = cv.imread('CoordCrom_1.png')\n",
    "img_cc_1_RGB = cv.cvtColor(img_cc_1_BGR, cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img_cc_1_RGB)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "635d51b6-6808-4031-acb3-cda1d0c63067",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cc_2_BGR = cv.imread('CoordCrom_2.png')\n",
    "img_cc_2_RGB = cv.cvtColor(img_cc_2_BGR, cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img_cc_2_RGB)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "638be885-864b-48f9-a048-de82c8b51160",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cc_3_BGR = cv.imread('CoordCrom_3.png')\n",
    "img_cc_3_RGB = cv.cvtColor(img_cc_3_BGR, cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img_cc_3_RGB)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df3232a-c091-4497-9048-4ba885609563",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumaRGB_cc1= np.sum(img_cc_1_RGB, axis=2, keepdims= True)\n",
    "sumaRGB_cc2= np.sum(img_cc_2_RGB, axis=2, keepdims= True)\n",
    "sumaRGB_cc3= np.sum(img_cc_3_RGB, axis=2, keepdims= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c21e96d-33eb-45d6-b4a1-067bd8e36348",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumaRGB_cc1 [sumaRGB_cc1==0]= 1\n",
    "sumaRGB_cc2 [sumaRGB_cc2==0]= 1\n",
    "sumaRGB_cc3 [sumaRGB_cc3==0]= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4db45635-cbff-4813-94e7-642471ff5114",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccrom_1 = img_cc_1_RGB / sumaRGB_cc1\n",
    "plt.imshow(ccrom_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e1b825e-04ae-4bf3-acb9-613439250f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccrom_2 = img_cc_2_RGB / sumaRGB_cc2\n",
    "plt.imshow(ccrom_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29b7da1c-6455-4fcb-99ff-baeb2dbdfec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccrom_3 = img_cc_3_RGB / sumaRGB_cc3\n",
    "plt.imshow(ccrom_3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03616540-1d88-4417-b610-581e8ffaeda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separación de coordenadas cromáticas para la imagen 1\n",
    "ccromatica_r = ccrom_1[:, :, 0]\n",
    "ccromatica_g = ccrom_1[:, :, 1]\n",
    "ccromatica_b = ccrom_1[:, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaecada8-c1f3-4f92-a682-dd2421bc3e3c",
   "metadata": {},
   "source": [
    "2.\r\n",
    "Implementar el algoritmo White\r\n",
    "Patch para librarnos de las diferencias de color de iluminación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33ad28da-253c-4a22-b870-fe0225157596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicación del algoritmo a la imagen wp_r\n",
    "img_r = cv.imread('wp_red.png')\n",
    "img_r = cv.cvtColor(img_r, cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ec55deb-ed03-4dfa-8bf7-a03bd057b601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 134 122\n"
     ]
    }
   ],
   "source": [
    "r_max= np.max(img_r[:,:,0])\n",
    "g_max= np.max(img_r[:,:,1])\n",
    "b_max= np.max(img_r[:,:,2])\n",
    "print(r_max, g_max, b_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "385cefdf-f0d9-4d60-9e65-ea6bf3217212",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_r = 255/r_max\n",
    "scale_g = 255/g_max\n",
    "scale_b = 255/b_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "698cbd79-b4e3-4393-82ba-56577c1c27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_r_scaled = cv.imread('wp_red.png')\n",
    "img_r_scaled = cv.cvtColor(img_r_scaled, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7081d5e9-4c8f-4b2b-8d09-ccd472044a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_r_scaled[:, :, 0] = img_r[:, :, 0]*scale_r\n",
    "img_r_scaled[:, :, 1] = img_r[:, :, 1]*scale_g\n",
    "img_r_scaled[:, :, 2] = img_r[:, :, 2]*scale_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d0e9940-1e6b-489c-b951-777668314c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_r_scaled)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "687780ca-a373-4d9a-8d5a-5c0dc821ec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 12))\n",
    "\n",
    "axs[0].imshow(img_r)\n",
    "axs[0].set_title('Imagen Original')\n",
    "\n",
    "axs[1].imshow(img_r_scaled)\n",
    "axs[1].set_title('Aplicando White Patch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e895a57-00d6-45a5-81f3-815f25fbf446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicación del algoritmo a la imagen wp_blue\n",
    "img_b = cv.imread('wp_blue.jpg')\n",
    "img_b = cv.cvtColor(img_b, cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img_b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1d153f82-571b-4583-9562-8310b3ac9adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 255 255\n"
     ]
    }
   ],
   "source": [
    "r_max= np.max(img_b[:,:,0])\n",
    "g_max= np.max(img_b[:,:,1])\n",
    "b_max= np.max(img_b[:,:,2])\n",
    "print(r_max, g_max, b_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b085cef-8a3d-4f0f-b269-8123c06dbda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_r = 255/r_max\n",
    "scale_g = 255/g_max\n",
    "scale_b = 255/b_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "44ac4512-0e58-4a82-b98d-afc05d950981",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_b_scaled = cv.imread('wp_blue.jpg')\n",
    "img_b_scaled = cv.cvtColor(img_b_scaled, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f15bf830-66b7-4bfb-8491-0f228468a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_b_scaled[:, :, 0] = img_b[:, :, 0]*scale_r\n",
    "img_b_scaled[:, :, 1] = img_b[:, :, 1]*scale_g\n",
    "img_b_scaled[:, :, 2] = img_b[:, :, 2]*scale_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "07e668e1-e46d-4c43-b13e-207251ebe79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_b_scaled)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f55ea95f-c745-4e58-a5c9-fa0bb62c800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 12))\n",
    "\n",
    "axs[0].imshow(img_b)\n",
    "axs[0].set_title('Imagen Original')\n",
    "\n",
    "axs[1].imshow(img_b_scaled)\n",
    "axs[1].set_title('Aplicando White Patch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428b9961-765a-4e98-851e-624e9594ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBLEMA CON WP: El máximo de cada canal es 255, por lo que el algoritmo no realiza transformación alguna. En cambio en wp_red,\n",
    "# el único que tiene máximo en 255 es el canal rojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5982c9e4-eb5e-42b4-b571-9576ee469166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicación del algoritmo a la imagen wp_green\n",
    "img_g = cv.imread('wp_green.png')\n",
    "img_g = cv.cvtColor(img_g, cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img_g)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e05ea7e5-a553-4176-bc73-cc70261a4f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 252 155\n"
     ]
    }
   ],
   "source": [
    "r_max= np.max(img_g[:,:,0])\n",
    "g_max= np.max(img_g[:,:,1])\n",
    "b_max= np.max(img_g[:,:,2])\n",
    "print(r_max, g_max, b_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9b4e0cfb-854d-43c6-ad4f-25b0a66c7eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_r = 255/r_max\n",
    "scale_g = 255/g_max\n",
    "scale_b = 255/b_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "12d68393-2bc0-4a2c-93f0-ae14bb84849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_g_scaled = cv.imread('wp_green.png')\n",
    "img_g_scaled = cv.cvtColor(img_g_scaled, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "814a6373-bdd4-43c1-84a7-0b36bcc305f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_g_scaled[:, :, 0] = img_g[:, :, 0]*scale_r\n",
    "img_g_scaled[:, :, 1] = img_g[:, :, 1]*scale_g\n",
    "img_g_scaled[:, :, 2] = img_g[:, :, 2]*scale_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aa7dada3-261a-4c71-8834-88c3cea5ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_g_scaled)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3354522e-42c2-43ac-af8b-6731aab73f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 12))\n",
    "\n",
    "axs[0].imshow(img_g)\n",
    "axs[0].set_title('Imagen Original')\n",
    "\n",
    "axs[1].imshow(img_g_scaled)\n",
    "axs[1].set_title('Aplicando White Patch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "12a2eabe-7a96-4ed8-b52d-5aad619c723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicación del algoritmo a la imagen wp_red2\n",
    "img_r2 = cv.imread('wp_red2.jpg')\n",
    "img_r2 = cv.cvtColor(img_r2, cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img_r2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1dc403cf-18e3-42cc-875c-b46331343364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 201 203\n"
     ]
    }
   ],
   "source": [
    "r_max= np.max(img_r2[:,:,0])\n",
    "g_max= np.max(img_r2[:,:,1])\n",
    "b_max= np.max(img_r2[:,:,2])\n",
    "print(r_max, g_max, b_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dfc4ae5c-9fd9-4659-943d-c700ab2f9a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_r = 255/r_max\n",
    "scale_g = 255/g_max\n",
    "scale_b = 255/b_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bcb05eec-fa3e-49a3-b6e9-9ba7abb1cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_r2_scaled = cv.imread('wp_red2.jpg')\n",
    "img_r2_scaled = cv.cvtColor(img_r2_scaled, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "11f657b1-98e2-4ac3-8495-d4e7397e7603",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_r2_scaled[:, :, 0] = img_r2[:, :, 0]*scale_r\n",
    "img_r2_scaled[:, :, 1] = img_r2[:, :, 1]*scale_g\n",
    "img_r2_scaled[:, :, 2] = img_r2[:, :, 2]*scale_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "08215581-7c01-42f4-bedc-92a9e563dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_r2_scaled)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "16e6aec5-7268-437c-ad63-17227db449ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 12))\n",
    "\n",
    "axs[0][0].imshow(img_r2)\n",
    "axs[0][0].set_title('Imagen Original Red 2')\n",
    "\n",
    "axs[0][1].imshow(img_r2_scaled)\n",
    "axs[0][1].set_title('Aplicando White Patch a Red 2')\n",
    "\n",
    "axs[1][0].imshow(img_r)\n",
    "axs[1][0].set_title('Imagen Original Red')\n",
    "\n",
    "axs[1][1].imshow(img_r_scaled)\n",
    "axs[1][1].set_title('Imagen Original Red')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Podemos ver que en la wp_red, los colores máximos en los canales b y g son menores, por lo que el escalado es mayor y se aprecian más detalles que en \n",
    "# el wp_red2 que tiene máximos más cercanos al 255 (255,201,203), siendo WP menos efectivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9d335df2-3d75-42b7-b6fe-3568d25e61fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicación del algoritmo a la imagen wp_green2\n",
    "img_g2 = cv.imread('wp_green2.jpg')\n",
    "img_g2 = cv.cvtColor(img_g2, cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img_g2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8f165e39-7f93-46c5-ad34-b9e5874bffd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170 255 172\n"
     ]
    }
   ],
   "source": [
    "r_max= np.max(img_g2[:,:,0])\n",
    "g_max= np.max(img_g2[:,:,1])\n",
    "b_max= np.max(img_g2[:,:,2])\n",
    "print(r_max, g_max, b_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "44297fba-e37a-4e78-94c7-b047a5427bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_r = 255/r_max\n",
    "scale_g = 255/g_max\n",
    "scale_b = 255/b_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dde24696-3c77-4fb1-b1a2-509ea51f29bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_g2_scaled = cv.imread('wp_green2.jpg')\n",
    "img_g2_scaled = cv.cvtColor(img_g2_scaled, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "abd53d94-73d6-40b2-9853-b78177a5503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_g2_scaled[:, :, 0] = img_g2[:, :, 0]*scale_r\n",
    "img_g2_scaled[:, :, 1] = img_g2[:, :, 1]*scale_g\n",
    "img_g2_scaled[:, :, 2] = img_g2[:, :, 2]*scale_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f9a2b0e0-c379-40bf-b0e9-dd69972c286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_g2_scaled)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0c092c67-0375-4ac5-8fb9-d537241eeac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 12))\n",
    "\n",
    "axs[0][0].imshow(img_g2)\n",
    "axs[0][0].set_title('Imagen Original Green 2')\n",
    "\n",
    "axs[0][1].imshow(img_g2_scaled)\n",
    "axs[0][1].set_title('Aplicando White Patch a Green 2')\n",
    "\n",
    "axs[1][0].imshow(img_g)\n",
    "axs[1][0].set_title('Imagen Original Green')\n",
    "\n",
    "axs[1][1].imshow(img_g_scaled)\n",
    "axs[1][1].set_title('Imagen Original Green')\n",
    "\n",
    "plt.show()\n",
    "#Sucede lo mismo a la comparación entre wp_red y wp_red2. En este caso wp_green tiene colores máximos mucho más próximos al 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4ac6fe7b-ad67-41bd-a67f-4092ddeb2a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicación del algoritmo WP a test_blue\n",
    "img_tb = cv.imread('test_blue.png')\n",
    "img_tb = cv.cvtColor(img_tb, cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img_tb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b4d24f12-92d7-4f70-9e84-dfae01562eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 138 200\n"
     ]
    }
   ],
   "source": [
    "r_max= np.max(img_tb[:,:,0])\n",
    "g_max= np.max(img_tb[:,:,1])\n",
    "b_max= np.max(img_tb[:,:,2])\n",
    "print(r_max,g_max,b_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f6d3c10f-1f8b-4ccb-ab1c-c8e45d236166",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_r = 255/r_max\n",
    "scale_g = 255/g_max\n",
    "scale_b = 255/b_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5c4b82e9-0909-46e4-84dd-3f858dbcf21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tb_scaled = cv.imread('test_blue.png')\n",
    "img_tb_scaled = cv.cvtColor(img_tb, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4ffd278e-c29d-453c-80be-4600eb7b4a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tb_scaled[:, :, 0] = img_tb[:, :, 0]*scale_r\n",
    "img_tb_scaled[:, :, 1] = img_tb[:, :, 1]*scale_g\n",
    "img_tb_scaled[:, :, 2] = img_tb[:, :, 2]*scale_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "63ebc6f3-81ae-4223-8891-2681db20ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_tb_scaled)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a88e8ce5-cf03-4338-948e-057a8f034cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 12))\n",
    "\n",
    "axs[0].imshow(img_tb)\n",
    "axs[0].set_title('Imagen Original')\n",
    "\n",
    "axs[1].imshow(img_tb_scaled)\n",
    "axs[1].set_title('Aplicando White Patch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "37c6b9db-66b9-4ac2-90bf-f4edfaae4fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicación del algoritmo WP a test_green\n",
    "img_tg = cv.imread('test_green.png')\n",
    "img_tg = cv.cvtColor(img_tg, cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img_tg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5b00773c-09d5-4a6a-8ce3-f3acfb627d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 250 171\n"
     ]
    }
   ],
   "source": [
    "r_max= np.max(img_tg[:,:,0])\n",
    "g_max= np.max(img_tg[:,:,1])\n",
    "b_max= np.max(img_tg[:,:,2])\n",
    "print(r_max,g_max,b_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c9038f57-dfd5-4754-83b6-abc6fe7fc668",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_r = 255/r_max\n",
    "scale_g = 255/g_max\n",
    "scale_b = 255/b_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "751ad536-6be2-432a-82ad-6e44d25f68a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tg_scaled = cv.imread('test_green.png')\n",
    "img_tg_scaled = cv.cvtColor(img_tg, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1f6c319b-ec01-4948-b14e-974b96dcc6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tg_scaled[:, :, 0] = img_tg[:, :, 0]*scale_r\n",
    "img_tg_scaled[:, :, 1] = img_tg[:, :, 1]*scale_g\n",
    "img_tg_scaled[:, :, 2] = img_tg[:, :, 2]*scale_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "21fae537-490b-42ba-b391-68200dc642ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_tg_scaled)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d4a1855b-82b3-45a5-a50c-0c0e151ffd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 12))\n",
    "\n",
    "axs[0].imshow(img_tg)\n",
    "axs[0].set_title('Imagen Original')\n",
    "\n",
    "axs[1].imshow(img_tg_scaled)\n",
    "axs[1].set_title('Aplicando White Patch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "65893e68-013c-4e0c-8297-696dae748f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicación del algoritmo WP a test_red\n",
    "img_tr = cv.imread('test_red.png')\n",
    "img_tr = cv.cvtColor(img_tr, cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img_tr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ca188e98-3f6d-47c3-881c-26cdd1ed4c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247 157 175\n"
     ]
    }
   ],
   "source": [
    "r_max= np.max(img_tr[:,:,0])\n",
    "g_max= np.max(img_tr[:,:,1])\n",
    "b_max= np.max(img_tr[:,:,2])\n",
    "print(r_max,g_max,b_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3586ae2e-75b9-4075-9e86-b4d2d1e54ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_r = 255/r_max\n",
    "scale_g = 255/g_max\n",
    "scale_b = 255/b_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f749943a-5faf-4db4-a9e7-d9a59f711f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tr_scaled = cv.imread('test_red.png')\n",
    "img_tr_scaled = cv.cvtColor(img_tr, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "62860fac-8d25-43ea-916f-997ed82c2467",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tr_scaled[:, :, 0] = img_tr[:, :, 0]*scale_r\n",
    "img_tr_scaled[:, :, 1] = img_tr[:, :, 1]*scale_g\n",
    "img_tr_scaled[:, :, 2] = img_tr[:, :, 2]*scale_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f8867860-6c24-4f56-8a76-cfc80febe82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_tr_scaled)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "26f95436-6f98-43c3-bbf8-0446c9e287f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 12))\n",
    "\n",
    "axs[0].imshow(img_tr)\n",
    "axs[0].set_title('Imagen Original')\n",
    "\n",
    "axs[1].imshow(img_tr_scaled)\n",
    "axs[1].set_title('Aplicando White Patch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5110b7c-fd94-4306-9621-3fd7bda06725",
   "metadata": {},
   "source": [
    "1.\r\n",
    "Para las imágenes\r\n",
    "img1_tp.png y img2_tp.png leerlas con OpenCV en escala de grisas y visualizarla\n",
    "2. Elija el numero de\r\n",
    "bins que crea conveniente y grafique su histograma, compare los histogramas entre si.\r\n",
    "Explicar lo que se observa, si tuviera que entrenar un modelo de clasificación/detección de imágenes,\r\n",
    "considera que puede ser de utilidad tomar como ‘ features ’ a loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "52b45c91-9a27-4a73-bd85-044b3d6c3402",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = cv.imread('img1_tp.png', cv.IMREAD_GRAYSCALE)\n",
    "img_1 = cv.cvtColor(img_1, cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0f97f55b-61ae-4ae0-a598-9f890f726d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_2 = cv.imread('img2_tp.png', cv.IMREAD_GRAYSCALE)\n",
    "img_2 = cv.cvtColor(img_2, cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "1a87eb34-dc32-4809-bf06-11231093edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "hist1, bins1 = np.histogram(img_1.ravel(), 256, [0, 256])\n",
    "plt.plot(hist1) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "250e4a60-937e-49f1-869b-abcde33b5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "hist2, bins2 = np.histogram(img_2.ravel(), 256, [0, 256])\n",
    "plt.plot(hist2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e049d553-3a94-4d55-b187-b93e934deed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estuve más de 15 minutos viendo el código ya que ambos histogramas son iguales y quería saber si tengo algún error, pero por lo que\n",
    "# veo, siendo imágenes tan diferentes, tienen la misma distribución. Teniendo la misma distribución no podrían ser utilizados como features\n",
    "# para un problema de clasificación.\n",
    "#Lo que se ve en los histogramas es saturación de blancos por la alta frecuencia en 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79182e5-d7f1-4dc2-b78d-f6b6c672b4d0",
   "metadata": {},
   "source": [
    "3. Para la imagen\r\n",
    "segmentacion.png analice el histograma de los canales RGB. Segmente algunos de los\r\n",
    "elementos presentes en la imagen (agua, cielo, tierra) y muestre, aplicando mascaras, las regiones en imágenes\r\n",
    "separadatado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c624a730-4dc2-46dc-92bc-f663c5c0266f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(628, 953, 3)\n"
     ]
    }
   ],
   "source": [
    "img_seg = cv.imread('segmentacion.png')\n",
    "img_seg = cv.cvtColor(img_seg, cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img_seg)\n",
    "plt.show()\n",
    "print(img_seg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "984a65c8-6bab-418c-89d6-90c918a6f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "hist_r,_=np.histogram(img_seg[:,:,0].ravel(), 256, [0,256])\n",
    "hist_g,_=np.histogram(img_seg[:,:,1].ravel(), 256, [0,256])\n",
    "hist_b,_=np.histogram(img_seg[:,:,2].ravel(), 256, [0,256])\n",
    "plt.plot(hist_r, color='red', label='Rojo')\n",
    "plt.plot(hist_g, color='green', label='Verde')\n",
    "plt.plot(hist_b, color='blue', label='Azul')\n",
    "plt.show()\n",
    "#El color rojo tiene sesgo a derecha (altas frecuencias con intensidad baja y muy pocas con alta intensidad), por lo que casi no impacta en la imagen. \n",
    "# El verde es simétrico, mientras que el azul es sesgado a izquierda, con alta intensidad, dadas por parte del mar y del cielo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9c7db85f-f7ad-4dd3-b213-bdb0a12ce987",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = cv.calcHist([img_seg], channels=[0, 1], mask=None, histSize=[256, 256], ranges=[0, 255, 0, 255])\n",
    "plt.figure()\n",
    "plt.imshow(hist, cmap='jet')\n",
    "plt.show()\n",
    "#Viendo el historgrama en 2D de rojo y verde, vemos que existe una correlación positiva bastante marcada hasta la intensidad aproximada de 150, que se corresponde\n",
    "# con los histogramas 1D. Luego, el rojo disminuye y el verde aumenta, por lo que la correlación cambia su pendiente, y se hace menos marcada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "059b2bc7-53f9-42c3-836d-66c058150fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = cv.calcHist([img_seg], channels=[1, 2], mask=None, histSize=[256, 256], ranges=[0, 255, 0, 255])\n",
    "plt.figure()\n",
    "plt.imshow(hist, cmap='jet')\n",
    "plt.show()\n",
    "\n",
    "#Correlación débil entre verde y azul en las intensidades bajas, luego cambia de pendiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "dac82e77-f8a4-4eb6-84a6-994695701e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = cv.calcHist([img_seg], channels=[0, 2], mask=None, histSize=[256, 256], ranges=[0, 255, 0, 255])\n",
    "plt.figure()\n",
    "plt.imshow(hist, cmap='jet')\n",
    "plt.show()\n",
    "#Solo hay correlación en las primeras intensidades cerca del 0, luego ya no existe casi correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a2737ca8-51e8-48bf-afcd-5fce5385ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_muestra_montaña = img_seg[450:600, 450:600,:]\n",
    "plt.figure(2)\n",
    "plt.imshow(img_muestra_montaña)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "abe54e73-0512-41b0-8a49-f10cc2bf6c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68.27231111]\n",
      " [54.27884444]\n",
      " [35.21173333]]\n",
      "[[50.22842955]\n",
      " [44.62724157]\n",
      " [34.13637441]]\n"
     ]
    }
   ],
   "source": [
    "color_mean, color_std = cv.meanStdDev(img_muestra_montaña)\n",
    "print(color_mean)\n",
    "print(color_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d20ea284-7c0d-4298-9eac-8387700869cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sigma = 1\n",
    "mask = cv.inRange(img_seg, color_mean-color_std * n_sigma,  color_mean+color_std * n_sigma)\n",
    "img_segmentada_montaña = cv.bitwise_and(img_seg, img_seg, mask=mask)\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(img_segmentada_montaña)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38e48b2-d36f-4b5e-903e-5f56ef8b3051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay que ponerle 1 sigma ya que con más sigmas toma parte de la playa. Para mí, es porque la media y la desv estándar están en los\n",
    "# mismos órdenes de magnitud, por lo que agranda mucho el rango de colores que toma y pasa del marrón al azul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5789bf6f-5ce8-45e7-b0a2-9031fd43abfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(628, 953, 3)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5d3a9f87-2f72-475d-ab8c-872ac477ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_muestra_cielo = img_seg[0:200,220:750,:]\n",
    "plt.figure(2)\n",
    "plt.imshow(img_muestra_cielo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ca57b7f8-53f7-4503-87a4-e57f81891869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 47.54386792]\n",
      " [144.78648113]\n",
      " [217.34075472]]\n",
      "[[54.35582366]\n",
      " [23.66480597]\n",
      " [11.0753227 ]]\n"
     ]
    }
   ],
   "source": [
    "color_mean, color_std = cv.meanStdDev(img_muestra_cielo)\n",
    "print(color_mean)\n",
    "print(color_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2c8e4107-5f3d-4cda-8afe-b49afd9ff3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sigma = 3.3\n",
    "mask = cv.inRange(img_seg, color_mean-color_std * n_sigma,  color_mean+color_std * n_sigma)\n",
    "img_segmentada_cielo = cv.bitwise_and(img_seg, img_seg, mask=mask)\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(img_segmentada_cielo)\n",
    "plt.show()\n",
    "#Varié la std desde 1 hasta 3.3. Con 1 y 2 toma muy poco del cielo. Con 2.5 deja una mancha negra a la derecha que se corresponde con los blancos.\n",
    "#Subiendo a 3, toma casi todos los blancos del cielo pero comienza a tomar los blancos de la espuma del mar. con 3.3 de std toma todo el cielo y\n",
    "#no varía casi la espuma del mar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2fd0c719-4a39-4d7f-a6e0-dac0dcd31271",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_muestra_cielo = img_seg[0:230,100:800,:]\n",
    "plt.figure(2)\n",
    "plt.imshow(img_muestra_cielo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f2dc5a2c-e550-4e79-9232-c0bf7a6741ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 49.60285714]\n",
      " [145.34484472]\n",
      " [215.80992547]]\n",
      "[[53.05960627]\n",
      " [24.69724558]\n",
      " [12.52074337]]\n"
     ]
    }
   ],
   "source": [
    "color_mean, color_std = cv.meanStdDev(img_muestra_cielo)\n",
    "print(color_mean)\n",
    "print(color_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c32cfce5-d4d6-43a2-85ba-82f983258fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sigma = 3\n",
    "mask = cv.inRange(img_seg, color_mean-color_std * n_sigma,  color_mean+color_std * n_sigma)\n",
    "img_segmentada_cielo = cv.bitwise_and(img_seg, img_seg, mask=mask)\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(img_segmentada_cielo)\n",
    "plt.show()\n",
    "\n",
    "#Aumentando la región de muestra no da un resultado significativamente diferente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c80c3ae0-065a-4416-9e7b-a5957f0255c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_muestra_mar = img_seg[280:420,400:500,:]\n",
    "plt.figure(2)\n",
    "plt.imshow(img_muestra_mar)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "34de9268-7238-41a0-8940-c1384ff0d3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 93.5285    ]\n",
      " [124.46535714]\n",
      " [134.87357143]]\n",
      "[[67.37551199]\n",
      " [51.63754116]\n",
      " [50.47236459]]\n"
     ]
    }
   ],
   "source": [
    "color_mean, color_std = cv.meanStdDev(img_muestra_mar)\n",
    "print(color_mean)\n",
    "print(color_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a24f975d-6577-47dc-8465-f6541c116cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sigma = 1.5\n",
    "mask = cv.inRange(img_seg, color_mean-1.5*color_std * n_sigma,  color_mean+color_std * 0.5*n_sigma)\n",
    "img_segmentada_mar = cv.bitwise_and(img_seg, img_seg, mask=mask)\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(img_segmentada_mar)\n",
    "plt.show()\n",
    "\n",
    "#Sucede algo similar con la segmentación de cielo, se mezclan los colores. La std debe ser como máximo 2 ya que ocn tres toma casi toda la imagen\n",
    "#al tener la muestra partes marrones de la costa, que con 3std toman la montaña\n",
    "#Si coloco diferentes sigmas para el limite superior e inferior, obtengo una mejor segmentación de la parte azul, pero falta la parte blanca\n",
    "# de la espuma de las olas. Si aumento el sigma superior, comienza a tomar el color azul claro del cielo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070e911-e197-49db-b575-94d7ab5fa9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
